[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "devansh’s blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nHistogram Equalization and Matching\n\n\n\n\n\n\ncode\n\n\nprobability theory\n\n\ncomputer vision\n\n\n\nThis post explores histogram matching and equalization between images of Elon Musk, Lenna, a Panda and the IIT Gandhinagar campus.\n\n\n\n\n\nDec 2, 2024\n\n\nDevansh Lodha\n\n\n\n\n\n\n\n\n\n\n\n\nOtsu’s Threshold Algorithm\n\n\n\n\n\n\ncode\n\n\nprobability theory\n\n\ncomputer vision\n\n\n\nWe’ll binarize images of Tom and Jerry, Pink Panther and some book pages. Then, we’ll challenge Otsu’s method with noisy inputs.\n\n\n\n\n\nDec 2, 2024\n\n\nDevansh Lodha\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/histogram_matching/histogram_matching.html",
    "href": "posts/histogram_matching/histogram_matching.html",
    "title": "Histogram Equalization and Matching",
    "section": "",
    "text": "Code\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nCode\npanda = cv2.imread(\"grey_1.png\",0)\nlenna = cv2.imread(\"grey_2.png\",0)\ncampus = cv2.imread(\"grey_3.png\",0)\nelon = cv2.imread(\"grey_4.png\",0)"
  },
  {
    "objectID": "posts/histogram_matching/histogram_matching.html#creating-the-histogram-of-an-image",
    "href": "posts/histogram_matching/histogram_matching.html#creating-the-histogram-of-an-image",
    "title": "Histogram Equalization and Matching",
    "section": "Creating the Histogram of an Image",
    "text": "Creating the Histogram of an Image\nWe have a discrete grayscale image \\(\\{x\\}\\) with \\(n_i\\) as the number of occurences of gray level \\(i\\). The probability of occurence of a pixel of level \\(i\\) in the image is \\[p_x(i)=p(x=i)=\\frac{n_i}{n}, \\qquad 0\\leq i &lt; L\\] where \\(L\\) is the total number of grey levels in the image (here \\(L=256\\)), \\(n\\) is the total number of pixels in the image (here \\(n = 512 \\times 512\\)), and \\(p_x(i)\\) is the image’s histogram for pixel value \\(i\\) normalized to \\([0,1]\\)\n\n\nCode\ndef imgToHist(img):\n  hist_data = np.zeros((256))\n  # counting number of pixels with a particular value between 0-255\n  for x_pixel in range(img.shape[0]):\n          for y_pixel in range(img.shape[1]):\n              pixel_value = int(img[x_pixel, y_pixel])\n              hist_data[pixel_value] += 1\n\n  # normalizing\n  hist_data/=(img.shape[0]*img.shape[1])\n\n  # returning the hist\n  return hist_data"
  },
  {
    "objectID": "posts/histogram_matching/histogram_matching.html#histogram-equalization",
    "href": "posts/histogram_matching/histogram_matching.html#histogram-equalization",
    "title": "Histogram Equalization and Matching",
    "section": "Histogram Equalization",
    "text": "Histogram Equalization\nWe define the cumulative distribution function corresponsing to \\(i\\) as \\[\\text{cdf}_x(i)=\\sum\\limits_{j=0}^{i}p_x(x=j)\\] which is also the image’s accumulated normalized histogram. \\ We would like to create a transformation of the form \\(y=T(x)\\) to produce a new image \\(\\{y\\}\\), with a flat histogram. Such as image would have a linearized cumulative distribution function across the value range \\[\\text{cdf}_y(i)=(i+1)K, \\qquad 0 \\leq i &lt; L\\] for some constant K. The properties of the CDF allow us to perform such a transform: \\[y = T(k) = \\text{cdf}_x(k)\\] where k is in the range \\([0, L-1]\\). \\(T\\) maps the levels into \\([0,1]\\) since we’re using normalized histogram of \\(\\{x\\}\\). In order to map the map the values into their original range, the following transformation needs to be applied: \\[y' = y \\cdot (\\text{max}\\{x\\} - \\text{min}\\{x\\}) + \\text{min}\\{x\\} = y \\cdot (L-1)\\] \\(y\\) is a real value while \\(y'\\) has to be integer. The mapped value \\(y'\\) should be \\(0\\) for the range of \\(0 &lt; y \\leq \\frac{1}{L}\\). And \\(y' = 1\\) for \\(\\frac{1}{L}&lt;y\\leq \\frac{2}{L}\\), \\(y' = 2\\) for \\(\\frac{2}{L}&lt;y\\leq \\frac{3}{L}\\), … \\(y' = L-1\\) for \\(\\frac{L-1}{L}&lt;y\\leq 1\\). Then the quantization formula for \\(y\\) to \\(y'\\) should be \\[y'=\\text{ceil}(L \\cdot y)-1\\] (\\(y'=-1\\) when \\(y=0\\), however, it does not happen just because \\(y=0\\) means that there is no pixel corresponding to that value.)\n\n\nCode\ndef equalize(img):\n  hist_data = imgToHist(img)\n  cdf_hist = np.cumsum(hist_data) # gives the CDF\n  equalized_hist = np.ceil(cdf_hist * 256) - 1 # maps back into original range\n  enhancedImg = np.zeros_like(img)\n  # now we need to replace initial pixel values with final pixel values\n  for x_pixel in range(img.shape[0]):\n          for y_pixel in range(img.shape[1]):\n              pixel_val = int(img[x_pixel, y_pixel])\n              enhancedImg[x_pixel, y_pixel] = equalized_hist[pixel_val]\n  return enhancedImg\n\n\nA function is defined to plot an images and their histograms before and after equalization. cmap is explicity defined to be gray since the default color map is virdis\n\n\nCode\ndef showEqualizedImg(image, enhanced_image):\n  source_histogram = imgToHist(image)\n  equalized_histogram = imgToHist(enhanced_image)\n  fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n  # source image\n  axes[0].imshow(image, cmap='gray')\n  axes[0].set_title('Source Image')\n  axes[0].axis('off')\n  # source histogram\n  axes[1].bar(np.arange(len(source_histogram)), source_histogram, color = \"Blue\")\n  axes[1].set_title('Source Histogram')\n  # equalized histogram\n  axes[2].bar(np.arange(len(equalized_histogram)), equalized_histogram, color = \"Red\")\n  axes[2].set_title('Equalized Histogram')\n  # enhanced image\n  axes[3].imshow(enhanced_image, cmap='gray')\n  axes[3].set_title('Enhanced Image')\n  axes[3].axis('off')\n\n  plt.tight_layout()\n  plt.show()\n\n\n\n\nCode\nshowEqualizedImg(panda, equalize(panda))\nshowEqualizedImg(lenna, equalize(lenna))\nshowEqualizedImg(campus, equalize(campus))\nshowEqualizedImg(elon, equalize(elon))"
  },
  {
    "objectID": "posts/histogram_matching/histogram_matching.html#histogram-matching",
    "href": "posts/histogram_matching/histogram_matching.html#histogram-matching",
    "title": "Histogram Equalization and Matching",
    "section": "Histogram Matching",
    "text": "Histogram Matching\nConsider a grayscale input image \\(X\\). It has a probability density function \\(p_r(r)\\), where \\(r\\) is a grayscale value, and \\(p_r(r)\\) is the probability of that value. This probability can easily be computed from the histogram of the image by \\[p_r(r_j)=\\frac{n_j}{n}\\] Where \\(n_j\\) is the frequency of the grayscale value \\(r_j\\), and \\(n\\) is the total number of pixels in the image. Now consider a desired output probability density function \\(p_z(z)\\). A transformation of \\(p_r(r)\\) is needed to convert it to \\(p_z(z)\\). \\ Each pdf (probability density function) can be mapped to its cumulative distribution function by \\[S(r_k)=\\sum\\limits_{j=0}^{k}p_r(r_j), \\qquad k =0,1,2,...,L-1\\] \\[G(z_k)=\\sum\\limits_{j=0}^{k}p_z(z_j), \\qquad k =0,1,2,...,L-1\\] Where L is the total number of gray levels (here \\(L=256\\)). \\ The idea is to map each \\(r\\) value in \\(X\\) to the \\(z\\) value that has the same probability in the desired pdf: \\[S(r_j) = G(z_i) \\text{ or } z = G^{-1}(S(r))\\]\nAlgorithm \\ Given two images, the reference and the target images, we compute their histograms. Following, we calculate the cumulative distribution functions of the two images’ histograms: \\(F_1\\) for for the reference image and \\(F_2\\) for the target image. Then for each gray level \\(G_1 \\in [0, 255]\\), we find the gray level \\(G_2\\) for which \\(F_1(G_1)=F_2(G_2)\\) and this is the result of histogram matching function: \\(M(G_1) = G_2\\). Finally, we apply the function \\(M\\) on each pixel of the reference image.\n\n\nCode\ndef match(source_image, target_image):\n  source_hist = imgToHist(source_image)\n  target_hist = imgToHist(target_image)\n  cdf_source_hist = np.cumsum(source_hist) # F1\n  cdf_target_hist = np.cumsum(target_hist) # F2\n  matched = np.zeros_like(source_image)\n  for x_pixel in range(source_image.shape[0]):\n    for y_pixel in range(source_image.shape[1]):\n      pixel_val = source_image[x_pixel, y_pixel] # G1\n      index = 255 # assume G2\n      # to find G2\n      for i in range(256):\n        if cdf_target_hist[i] - cdf_source_hist[pixel_val] &gt;= 0:\n          index = i\n          break\n      # applying function on each pixel\n      matched[x_pixel, y_pixel] = index\n  return matched\n\n\nA function is defined to source image, target image and image obtained upon matching. \\ cmap is explicity defined to be gray since the default color map is virdis\n\n\nCode\ndef showMatchedImg(source_img, target_img, matched_img):\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    # source image\n    axes[0].imshow(source_img, cmap='gray')\n    axes[0].set_title('Source Image')\n    axes[0].axis('off')\n    # target image\n    axes[1].imshow(target_img, cmap='gray')\n    axes[1].set_title('Target Image')\n    axes[1].axis('off')\n    # matched image\n    axes[2].imshow(matched_img, cmap='gray')\n    axes[2].set_title('Matched Image')\n    axes[2].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\ndef imageMatch(sourceImage, targetImage):\n  matchedImage = match(sourceImage, targetImage)\n  showMatchedImg(sourceImage, targetImage, matchedImage)\n# according to submission requirements\nimageMatch(panda, lenna)\nimageMatch(elon, campus)\nimageMatch(lenna, elon)\nimageMatch(campus, panda)"
  },
  {
    "objectID": "posts/histogram_matching/histogram_matching.html#references",
    "href": "posts/histogram_matching/histogram_matching.html#references",
    "title": "Histogram Equalization and Matching",
    "section": "References",
    "text": "References\n[1] Wikipedia Contributors, “Histogram equalization,” Wikipedia, May 18, 2018. https://en.wikipedia.org/wiki/Histogram_equalization\n[2] “Histogram matching,” Wikipedia, Feb. 07, 2022. https://en.wikipedia.org/wiki/Histogram_matching"
  },
  {
    "objectID": "posts/otsu_thresholding/otsu_thresholding.html",
    "href": "posts/otsu_thresholding/otsu_thresholding.html",
    "title": "Otsu’s Threshold Algorithm",
    "section": "",
    "text": "The Otsu method is used to find the threshold value for a grayscale image. The threshold value is used to separate the image into two parts: the background and the foreground. The Otsu method is based on the assumption that the image has two classes of pixels: the background and the foreground. The method calculates the threshold value that minimizes the intra-class variance and maximizes the inter-class variance. The threshold value is used to separate the image into two parts: the background and the foreground. The Otsu method is widely used in image processing and computer vision applications.\nCode\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nCode\nbookpage_1 = cv2.imread(\"bookpage_1.jpeg\",0)\nbookpage_2 = cv2.imread(\"bookpage_2.jpeg\",0)\npanther = cv2.imread(\"panther.jpeg\",0)\ntom = cv2.imread(\"tom.jpeg\",0)"
  },
  {
    "objectID": "posts/otsu_thresholding/otsu_thresholding.html#creating-the-histogram-of-an-image",
    "href": "posts/otsu_thresholding/otsu_thresholding.html#creating-the-histogram-of-an-image",
    "title": "Otsu’s Threshold Algorithm",
    "section": "Creating the Histogram of an Image",
    "text": "Creating the Histogram of an Image\nWe have a discrete grayscale image \\(\\{x\\}\\) with \\(n_i\\) as the number of occurences of gray level \\(i\\). The probability of occurence of a pixel of level \\(i\\) in the image is \\[p_x(i)=p(x=i)=\\frac{n_i}{n}, \\qquad 0\\leq i &lt; L\\] where \\(L\\) is the total number of grey levels in the image (here \\(L=256\\)), \\(n\\) is the total number of pixels in the image, and \\(p_x(i)\\) is the image’s histogram for pixel value \\(i\\) normalized to \\([0,1]\\)\n\n\nCode\ndef imgToHist(img):\n  hist_data = np.zeros((256))\n  # counting number of pixels with a particular value between 0-255\n  for x_pixel in range(img.shape[0]):\n          for y_pixel in range(img.shape[1]):\n              pixel_value = int(img[x_pixel, y_pixel])\n              hist_data[pixel_value] += 1\n\n  # normalizing\n  hist_data/=(img.shape[0]*img.shape[1])\n\n  # returning the hist\n  return hist_data"
  },
  {
    "objectID": "posts/otsu_thresholding/otsu_thresholding.html#implementing-otsus-algorithm",
    "href": "posts/otsu_thresholding/otsu_thresholding.html#implementing-otsus-algorithm",
    "title": "Otsu’s Threshold Algorithm",
    "section": "Implementing Otsu’s Algorithm",
    "text": "Implementing Otsu’s Algorithm\nThe algorithm exhaustively searches for the threshold that minimizes the intra-class variance, defined as a weighted sum of variances of the two classes: \\[\\sigma_w^2 (t) = w_0(t)\\sigma_0^2 (t)+w_1(t)\\sigma_1^2 (t)\\] Weights \\(w_0\\) and \\(w_1\\) are the probabilities of the two classes separated by a threshold \\(t\\), and \\(\\sigma_0^2\\) and \\(\\sigma_1^2\\) are variance of these two classes. The class probability \\(w_{\\{0,1\\}}(t)\\) is computed from the \\(L\\) bins of the histogram: \\[w_0(t) = \\sum\\limits_{i=0}^{t-1}p(i)\\] \\[w_1(t) = \\sum\\limits_{i=t}^{L-1}p(i)\\] For two classes, minimized the intra-class variance is equivalent to maximizing inter-class variance: \\[\\sigma_b^2(t) = \\sigma^2 -\\sigma_w^2(t) = w_0(t)(\\mu_0-\\mu_T)^2 + w_1(t)(\\mu_1-\\mu_T)^2 = w_0(t)w_1(t)[\\mu_0(t)-\\mu_1(t)]^2\\] which is expressed in terms of class probabilities \\(w\\) and class means \\(\\mu\\) where the class means \\(\\mu_0(t)\\), \\(\\mu_1(t), \\mu_T\\) are: \\[\\mu_0(t) = \\frac{\\sum\\limits_{i=0}^{t-1}ip(i)}{w_0(t)}\\] \\[\\mu_1(t) = \\frac{\\sum\\limits_{i=t}^{L-1}ip(i)}{w_1(t)}\\] \\[\\mu_T = \\sum\\limits_{i=0}^{L-1}ip(i)\\]\n\nAlgorithm\n\nCompute histogram and probabilites of each intensity level\nSet up initial w_i(0) and u_i(0)\nStep through all possible thresholds \\(t=1,...,\\text{maximum intensity}\\)\nUpdate \\(w_i\\) and \\(\\mu_i\\)\nCompute \\(\\sigma_b^2(t)\\)\nDesired threshold corresponds to maximum \\(\\sigma_b^2(t)\\)\n\n\n\nCode\ndef otsu(img):\n  hist = imgToHist(img)\n  inter_class_variances = []\n  for i in range(256):\n    w0 = sum(hist[0:i])\n    w1 = sum(hist[i:])\n    u0 = sum([x*hist[x]/w0 for x in range(0,i)])\n    u1 = sum([x*hist[x]/w1 for x in range(i,256)])\n    sigma0 = sum([((x-u0)**2)*hist[x] for x in range(0,i)])\n    sigma1 = sum([((x-u1)**2)*hist[x] for x in range(i,256)])\n    sigmaw = w0*sigma0 + w1*sigma1\n    sigmab=w0*w1*(u0-u1)**2\n    inter_class_variances.append(sigmab)\n  # maximizing inter-class variance\n  threshold = inter_class_variances.index(max(inter_class_variances))\n  binarized_image = np.zeros_like(img)\n  for x_pixel in range(img.shape[0]):\n          for y_pixel in range(img.shape[1]):\n              pixel_value = int(img[x_pixel, y_pixel])\n              if pixel_value &gt; threshold:\n                binarized_image[x_pixel, y_pixel] = 255\n              else:\n                binarized_image[x_pixel, y_pixel] = 0\n  return threshold, binarized_image\n\n\n\n\nCode\ndef showBinarizedImg(source_img):\n    fig, axes = plt.subplots(1, 2, figsize=(6, 4))\n    # source image\n    axes[0].imshow(source_img, cmap='gray')\n    axes[0].set_title(r'Source Image')\n    axes[0].axis('off')\n    \n    # binarized image\n    threshold, binarized_img = otsu(source_img)\n    axes[1].imshow(binarized_img, cmap='gray')\n    axes[1].set_title(r\"Binarized Image\")\n    axes[1].axis('off')\n\n    # figure title based on threshold with LaTeX formatting\n    fig.suptitle(fr\"Otsu's Threshold: ${threshold}$\", fontsize=12)\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\nshowBinarizedImg(bookpage_1)\nshowBinarizedImg(bookpage_2)\nshowBinarizedImg(panther)\nshowBinarizedImg(tom)"
  },
  {
    "objectID": "posts/otsu_thresholding/otsu_thresholding.html#adding-gaussian-noise-and-applying-otsus-algorithm",
    "href": "posts/otsu_thresholding/otsu_thresholding.html#adding-gaussian-noise-and-applying-otsus-algorithm",
    "title": "Otsu’s Threshold Algorithm",
    "section": "Adding Gaussian Noise and Applying Otsu’s Algorithm",
    "text": "Adding Gaussian Noise and Applying Otsu’s Algorithm\nBy adding noise to an image, we can simulate real-world scenarios where images are often corrupted by various noise sources (e.g., sensor noise, transmission errors). This allows us to evaluate how well Otsu’s method performs under different noise conditions and its robustness to noise.\n\n\nCode\ndef addGaussianNoise(img, variance):\n  mean = 0.0\n  std = np.sqrt(variance)\n  noisy_img = img + np.random.normal(mean, std, img.shape)\n  noisy_img_clipped = np.clip(noisy_img, 0, 255 )\n  return noisy_img_clipped\n\n\n\n\nCode\ndef showBinarizedImgWithNoise(source_img, variance):\n    threshold, binarized_img = otsu(source_img)\n    noisy_source_img = addGaussianNoise(source_img, variance)\n    noisy_threshold, binarized_noisy_img = otsu(noisy_source_img)\n    \n    fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n\n    # Source and Binarized Image Titles (without noise)\n    source_title = r\"Source Image\"\n    binary_title = fr\"Binarized Image (Threshold: ${threshold}$)\"\n\n    # Noisy Source and Binarized Image Titles (with noise)\n    noisy_source_title = fr\"Source Image with Noise ($\\sigma^2={variance}$)\"\n    noisy_binary_title = fr\"Binarized Image (Threshold: ${noisy_threshold}$)\"\n\n    # Source image\n    axes[0].imshow(source_img, cmap='gray')\n    axes[0].set_title(source_title)\n    axes[0].axis('off')\n\n    # Binarized image\n    axes[1].imshow(binarized_img, cmap='gray')\n    axes[1].set_title(binary_title)\n    axes[1].axis('off')\n\n    # Source image with noise\n    axes[2].imshow(noisy_source_img, cmap='gray')\n    axes[2].set_title(noisy_source_title)\n    axes[2].axis('off')\n\n    # Binarized image with noise\n    axes[3].imshow(binarized_noisy_img, cmap='gray')\n    axes[3].set_title(noisy_binary_title)\n    axes[3].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\nvar = 1000\nshowBinarizedImgWithNoise(bookpage_1, var)\nshowBinarizedImgWithNoise(bookpage_2, var)\nshowBinarizedImgWithNoise(panther, var)\nshowBinarizedImgWithNoise(tom, var)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe threshold value obtained from Otsu’s method may vary significantly depending on the noise level. Higher noise levels can lead to less accurate thresholding.\nThe quality of the binarized image can degrade with increasing noise. Noisy pixels can be incorrectly classified as foreground or background, leading to a loss of detail and accuracy.\nBy analyzing the results under different noise levels, we can assess the robustness of Otsu’s method. Some variations of Otsu’s method, such as adaptive thresholding, may be more resilient to noise.\nWe might consider pre-processing techniques like noise reduction filters to improve the input image quality before applying Otsu’s method."
  },
  {
    "objectID": "posts/otsu_thresholding/otsu_thresholding.html#references",
    "href": "posts/otsu_thresholding/otsu_thresholding.html#references",
    "title": "Otsu’s Threshold Algorithm",
    "section": "References",
    "text": "References\nWikipedia Contributors, “Otsu’s method,” Wikipedia, Aug. 16, 2020. https://en.wikipedia.org/wiki/Otsu%27s_method"
  }
]